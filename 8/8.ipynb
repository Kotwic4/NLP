{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "The task concentrates on content-based text the classification.\n",
    "\n",
    "\n",
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the set of bills into two exclusive sets:\n",
    "   1. the set of bills amending other bills (their title starts with `o zmianie ustawy`),\n",
    "   1. the set of bills not amending other bills.\n",
    "\n",
    "### Change the contents of the bill by removing the date of publication and the title (so the words `o zmianie ustawy` are removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import os\n",
    "import requests\n",
    "from collections import Counter\n",
    "from operator import add\n",
    "import functools\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filesNames():\n",
    "    path = '../ustawy'\n",
    "    absolute_path = os.path.realpath(path) + \"\\\\\"\n",
    "    return [(absolute_path + filename, filename) for filename in os.listdir(path)]\n",
    "\n",
    "def getFileTextRaw(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as content_file:\n",
    "        return regex.sub(r\"\\n\\s*\\n\", \"\\n\", content_file.read()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found for: 1996_400.txt\n",
      "713 466\n"
     ]
    }
   ],
   "source": [
    "def splitTitle(text):\n",
    "    search = regex.search(r'((Art.)|(Rozdział))(\\s+1)',text)\n",
    "    if search is None:\n",
    "        return None, None\n",
    "    return (text[:search.start()], text[search.start():])\n",
    "\n",
    "def splitByTemp(text):\n",
    "    search = regex.search(r'(zmianie|zmieniająca)(.|\\n)*(ustaw|ustawy)',text)\n",
    "    if search is None:\n",
    "        return None\n",
    "    return text[:search.start()]\n",
    "\n",
    "possitive = []\n",
    "negative = []\n",
    "\n",
    "for (path, filename) in filesNames():\n",
    "    text = getFileTextRaw(path)\n",
    "    title, body = splitTitle(text)\n",
    "    if title is None:\n",
    "        print(\"Not found for: \" + filename)\n",
    "    else:\n",
    "        result = splitByTemp(title)\n",
    "        if result is None:\n",
    "            negative.append((body,0))\n",
    "        else:\n",
    "            possitive.append((body,1))\n",
    "print(len(possitive), len(negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the sets of documents into the following groups by randomly selecting the documents:\n",
    "   1. 60% training\n",
    "   1. 20% validation\n",
    "   1. 20% testing\n",
    "   \n",
    "### Do not change these groups during the following experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_possitive = possitive[:]\n",
    "random_negative = negative[:]\n",
    "random.shuffle(random_possitive)\n",
    "random.shuffle(random_negative)\n",
    "\n",
    "possitive_training_number = math.floor(len(random_possitive)*0.6)\n",
    "possitive_validation_number = math.floor(len(random_possitive)*0.8)\n",
    "\n",
    "negative_training_number = math.floor(len(random_negative)*0.6)\n",
    "negative_validation_number = math.floor(len(random_negative)*0.8)\n",
    "\n",
    "\n",
    "training_positive = random_possitive[:possitive_training_number]\n",
    "training_negative = random_negative[:negative_training_number]\n",
    "training_set = training_positive[:] + training_negative[:]\n",
    "random.shuffle(training_set)\n",
    "\n",
    "validation_positive = random_possitive[possitive_training_number:possitive_validation_number]\n",
    "validation_negative = random_negative[negative_training_number:negative_validation_number]\n",
    "validation_set = validation_positive[:] + validation_negative[:]\n",
    "random.shuffle(validation_set)\n",
    "\n",
    "testing_positive = random_possitive[possitive_validation_number:]\n",
    "testing_negative = random_negative[negative_validation_number:]\n",
    "testing_set = testing_positive[:] + testing_negative[:]\n",
    "random.shuffle(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the following variants of the documents:\n",
    "   1. full text of the document\n",
    "   1. randomly selected 10% of the lines of the document\n",
    "   1. randomly selected 10 lines of the document\n",
    "   1. randomly selected 1 line of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(text, number):\n",
    "    lines = text.split('\\n')\n",
    "    if len(lines) < number:\n",
    "        return lines\n",
    "    return random.sample(lines,number)\n",
    "\n",
    "def get_line_percetage(text, number):\n",
    "    lines = text.split('\\n')\n",
    "    return random.sample(lines, math.ceil(len(lines)*number))\n",
    "\n",
    "def prepare_a(data_set):\n",
    "    return [(text, result) for (text, result) in data_set]\n",
    "\n",
    "def prepare_b(data_set):\n",
    "    return [(\"\\n\".join(get_line_percetage(text, 0.1)), result) for (text, result) in data_set]\n",
    "\n",
    "def prepare_c(data_set):\n",
    "    return [(\"\\n\".join(get_lines(text, 10)), result) for (text, result) in data_set]\n",
    "\n",
    "def prepare_d(data_set):\n",
    "    return [(\"\\n\".join(get_lines(text, 1)), result) for (text, result) in data_set]\n",
    "\n",
    "training_set_a = prepare_a(training_set)\n",
    "training_set_b = prepare_b(training_set)\n",
    "training_set_c = prepare_c(training_set)\n",
    "training_set_d = prepare_d(training_set)\n",
    "\n",
    "validation_set_a = prepare_a(validation_set)\n",
    "validation_set_b = prepare_b(validation_set)\n",
    "validation_set_c = prepare_c(validation_set)\n",
    "validation_set_d = prepare_d(validation_set)\n",
    "\n",
    "testing_set_a = prepare_a(testing_set)\n",
    "testing_set_b = prepare_b(testing_set)\n",
    "testing_set_c = prepare_c(testing_set)\n",
    "testing_set_d = prepare_d(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the following classifiers on the documents:\n",
    "\n",
    "   1. SVM with TF•IDF\n",
    "   1. Fasttext\n",
    "   1. Flair with Polish language model\n",
    "   \n",
    "### Report Precision, Recall and F1 for each variant of the experiment (12 variants altogether)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art. 1. W ustawie z dnia 19\n",
      "lutego 1993 r. o znakach Sił Zbrojnych Rzeczypospolitej Polskiej (Dz. U. z 2015\n",
      "r. poz. 1863) wprowadza się następujące zmiany:\n",
      "1)     w\n",
      "art. 1 w ust. 1:\n",
      "a)     w\n",
      "pkt 1 w lit. d średnik zastępuje się przecinkiem i dodaje się lit. e w\n",
      "brzmieniu:\n",
      "„e)   orzeł wojsk obrony terytorialnej;”,\n",
      "b)    w pkt 5\n",
      "w lit. d kropkę zastępuje się przecinkiem i dodaje się lit. e w brzmieniu:\n",
      "„e)   flaga wojsk obrony\n",
      "terytorialnej.”;\n",
      "2)    \n",
      "po art. 7a dodaje się art. 7b w brzmieniu:\n",
      "„Art. 7b. 1. Orłem wojsk obrony\n",
      "terytorialnej jest orzeł określony w art. 5, z umieszczonym na tarczy\n",
      "amazonek złotym Znakiem Polski Walczącej.\n",
      "2. Wzór orła wojsk obrony terytorialnej\n",
      "zawiera załącznik nr 3b.”;\n",
      "3)     w\n",
      "art. 25 ust. 3 otrzymuje brzmienie:\n",
      "„3. Wzory flag rodzajów sił zbrojnych\n",
      "zawierają załączniki nr 12–16.”;\n",
      "4)     po załączniku nr 3a dodaje się\n",
      "załącznik nr 3b w brzmieniu określonym w załączniku nr 1 do niniejszej ustawy;\n",
      "5)     dodaje się załącznik nr 16 w\n",
      "brzmieniu określonym w załączniku nr 2 do niniejszej ustawy.\n",
      "Art. 2. Ustawa\n",
      "wchodzi w życie po upływie 14 dni od dnia ogłoszenia.\n",
      "MARSZAŁEK\n",
      "SEJMU\n",
      "/ – / Marek Kuchciński\n",
      "Załączniki\n",
      "do\n",
      "ustawy z dnia 10 maja 2018 r.\n",
      "(poz.\n",
      "…)\n",
      "Załącznik nr 1\n",
      "ORZEŁ\n",
      "WOJSK OBRONY TERYTORIALNEJ\n",
      "Załącznik nr 2\n",
      "FLAGA\n",
      "WOJSK OBRONY TERYTORIALNEJ\n",
      "strona główna\n",
      "         1:2, 1\n",
      "strona odwrotna\n"
     ]
    }
   ],
   "source": [
    "print(training_set_a[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "\n",
    "1. Application of SVM classifier with TF•IDF is described in \n",
    "   [David Batista](http://www.davidsbatista.net/blog/2017/04/01/document_classification/) blog post.\n",
    "1. [Fasttext](https://fasttext.cc/) is a popular basline classifier. Don't report the Precision/Recall/F1 provided by\n",
    "   Fasttext since they might be [wrong](https://github.com/facebookresearch/fastText/issues/261).\n",
    "1. [Flair](https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f) \n",
    "   is another library for text processing. Flair classification is based on a language model.\n",
    "1. [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) by Jurafsky and Martin \n",
    "   has a [chapter](https://web.stanford.edu/~jurafsky/slp3/4.pdf) devoted to the problem of classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
