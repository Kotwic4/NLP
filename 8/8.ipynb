{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "The task concentrates on content-based text the classification.\n",
    "\n",
    "\n",
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the set of bills into two exclusive sets:\n",
    "   1. the set of bills amending other bills (their title starts with `o zmianie ustawy`),\n",
    "   1. the set of bills not amending other bills.\n",
    "\n",
    "### Change the contents of the bill by removing the date of publication and the title (so the words `o zmianie ustawy` are removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import os\n",
    "import requests\n",
    "from collections import Counter\n",
    "from operator import add\n",
    "import functools\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filesNames():\n",
    "    path = '../ustawy'\n",
    "    absolute_path = os.path.realpath(path) + \"\\\\\"\n",
    "    return [(absolute_path + filename, filename) for filename in os.listdir(path)]\n",
    "\n",
    "def getFileTextRaw(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as content_file:\n",
    "        return content_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found for: 1996_400.txt\n",
      "713 466\n"
     ]
    }
   ],
   "source": [
    "def splitTitle(text):\n",
    "    search = regex.search(r'((Art.)|(Rozdział))(\\s+1)',text)\n",
    "    if search is None:\n",
    "        return None\n",
    "    return text[:search.start()]\n",
    "\n",
    "def splitByTemp(text):\n",
    "    search = regex.search(r'(zmianie|zmieniająca)(.|\\n)*(ustaw|ustawy)',text)\n",
    "    if search is None:\n",
    "        return None\n",
    "    return text[:search.start()]\n",
    "\n",
    "possitive = []\n",
    "negative = []\n",
    "\n",
    "for (path, filename) in filesNames():\n",
    "    text = getFileTextRaw(path)\n",
    "    title = splitTitle(text)\n",
    "    if title is None:\n",
    "        print(\"Not found for: \" + filename)\n",
    "    else:\n",
    "        result = splitByTemp(title)\n",
    "        if result is None:\n",
    "            negative.append((text,0))\n",
    "        else:\n",
    "            possitive.append((text,1))\n",
    "print(len(possitive), len(negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the sets of documents into the following groups by randomly selecting the documents:\n",
    "   1. 60% training\n",
    "   1. 20% validation\n",
    "   1. 20% testing\n",
    "   \n",
    "### Do not change these groups during the following experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_possitive = possitive[:]\n",
    "random_negative = negative[:]\n",
    "random.shuffle(random_possitive)\n",
    "random.shuffle(random_negative)\n",
    "\n",
    "possitive_training_number = math.floor(len(random_possitive)*0.6)\n",
    "possitive_validation_number = math.floor(len(random_possitive)*0.8)\n",
    "\n",
    "negative_training_number = math.floor(len(random_negative)*0.6)\n",
    "negative_validation_number = math.floor(len(random_negative)*0.8)\n",
    "\n",
    "\n",
    "training_positive = random_possitive[:possitive_training_number]\n",
    "training_negative = random_negative[:negative_training_number]\n",
    "training_set = (training_positive, training_negative)\n",
    "\n",
    "validation_positive = random_possitive[possitive_training_number:possitive_validation_number]\n",
    "validation_negative = random_negative[negative_training_number:negative_validation_number]\n",
    "validation_set = (validation_positive, validation_negative)\n",
    "\n",
    "testing_positive = random_possitive[possitive_validation_number:]\n",
    "testing_negative = random_negative[negative_validation_number:]\n",
    "testing_set = (testing_positive, testing_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the following variants of the documents:\n",
    "   1. full text of the document\n",
    "   1. randomly selected 10% of the lines of the document\n",
    "   1. randomly selected 10 lines of the document\n",
    "   1. randomly selected 1 line of the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the following classifiers on the documents:\n",
    "\n",
    "   1. SVM with TF•IDF\n",
    "   1. Fasttext\n",
    "   1. Flair with Polish language model\n",
    "   \n",
    "### Report Precision, Recall and F1 for each variant of the experiment (12 variants altogether)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "\n",
    "1. Application of SVM classifier with TF•IDF is described in \n",
    "   [David Batista](http://www.davidsbatista.net/blog/2017/04/01/document_classification/) blog post.\n",
    "1. [Fasttext](https://fasttext.cc/) is a popular basline classifier. Don't report the Precision/Recall/F1 provided by\n",
    "   Fasttext since they might be [wrong](https://github.com/facebookresearch/fastText/issues/261).\n",
    "1. [Flair](https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f) \n",
    "   is another library for text processing. Flair classification is based on a language model.\n",
    "1. [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) by Jurafsky and Martin \n",
    "   has a [chapter](https://web.stanford.edu/~jurafsky/slp3/4.pdf) devoted to the problem of classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
