{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download [docker image](https://hub.docker.com/r/djstrong/krnnt2) of KRNNT2. It includes the following tools:\n",
    "   1. Morfeusz2 - morphological dictionary\n",
    "   1. Corpus2 - corpus access library\n",
    "   1. Toki - tokenizer for Polish\n",
    "   1. Maca - morphosyntactic analyzer\n",
    "   1. rknnt - Polish tagger\n",
    "1. Use the tool to tag and lemmatize the corpus with the bills.\n",
    "1. Using the tagged corpus compute bigram statistic for the tokens containing:\n",
    "   1. lemmatized, downcased word\n",
    "   1. morphosyntactic category of the word (noun, verb, etc.)\n",
    "1. Exclude bigram containing non-words (such as numbers, punctuation, etc.)\n",
    "1. For example: \"Ala ma kota\", which is tagged as:\n",
    "   ```\n",
    "   Ala\tnone\n",
    "           Ala\tsubst:sg:nom:f\tdisamb\n",
    "   ma\tspace\n",
    "           mieć\tfin:sg:ter:imperf\tdisamb\n",
    "   kota\tspace\n",
    "           kot\tsubst:sg:acc:m2\tdisamb\n",
    "   .\tnone\n",
    "           .\tinterp\tdisamb\n",
    "   ```\n",
    "   the algorithm should return the following bigrams: `ala:subst mieć:fin` and `mieć:fin kot:subst`.\n",
    "1. Compute LLR statistic for this dataset.\n",
    "1. Select top 50 results including noun at the first position and noun or adjective at the second position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import regex\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def filesNames():\n",
    "    path = '../ustawy'\n",
    "    absolute_path = os.path.realpath(path) + \"\\\\\"\n",
    "    return [(absolute_path + filename, filename) for filename in os.listdir(path)]\n",
    "\n",
    "def getFileTextRaw(path):\n",
    "    with open(path, 'r', encoding=\"utf8\") as content_file:\n",
    "        return content_file.read()\n",
    "    \n",
    "def cleanText(text):\n",
    "    lower_text = text.replace('-\\n', '').replace('\\n', ' ').lower()\n",
    "    unpunct_text = regex.sub(r\"\\p{P}\", ' ' ,lower_text)\n",
    "    without_empty_text = regex.sub(r\"\\s+\", ' ' ,unpunct_text).strip()\n",
    "    return without_empty_text\n",
    "\n",
    "def lematText(text):\n",
    "    url = 'http://localhost:9200'\n",
    "    data = text.encode('utf-8')\n",
    "    return requests.post(url=url, data=data).content.decode('utf-8')\n",
    "\n",
    "def splitWords(lemat_text):\n",
    "    words = []\n",
    "#     assertion that there is always 4\n",
    "#     prev = 0\n",
    "    for line in lemat_text.splitlines():\n",
    "        splitted = line.split('\\t')\n",
    "        splitted_len = len(splitted)\n",
    "        if splitted_len == 4:\n",
    "            words.append((splitted[1], splitted[2].split(':')[0]))\n",
    "#         if prev == splitted_len:\n",
    "#             print(splitted, splitted_len)\n",
    "#             break\n",
    "#         prev = len(splitted)\n",
    "    return words\n",
    "\n",
    "def correctWord(word):\n",
    "    return word[0].isalpha()\n",
    "\n",
    "def countsBigrams(words, bigram_counter, left_counter, right_counter):\n",
    "    bigram_size = 0\n",
    "    for index, right_word in enumerate(words[1:]):\n",
    "        left_word = words[index-1]\n",
    "        if correctWord(right_word) and correctWord(left_word):\n",
    "            bigram_counter[(left_word, right_word)] += 1\n",
    "            left_counter[left_word] +=1\n",
    "            right_counter[right_word] +=1\n",
    "            bigram_size += 1\n",
    "    return bigram_size\n",
    "\n",
    "def shannon(values, N):\n",
    "    return sum([k / N * math.log(k/N + (k == 0)) for k in values])\n",
    "\n",
    "def llr(bigram, val, left_counter, right_counter, bigram_size):\n",
    "    k_11 = val\n",
    "    k_12 = right_counter[bigram[1]] - val\n",
    "    k_21 = left_counter[bigram[0]] - val\n",
    "    k_22 = bigram_size - right_counter[bigram[1]] - left_counter[bigram[0]] + val\n",
    "    return 2 * bigram_size * (shannon([k_11, k_12, k_21, k_22], bigram_size) - shannon([k_11 + k_12, k_21 + k_22], bigram_size) - shannon([k_11 + k_21, k_12 + k_22], bigram_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_counter = Counter()\n",
    "left_counter = Counter()\n",
    "right_counter = Counter()\n",
    "bigram_size = 0\n",
    "for (path, filename) in filesNames():\n",
    "    content = getFileTextRaw(path)\n",
    "    clean_text = cleanText(content)\n",
    "    lemat_text = lematText(clean_text)\n",
    "    words = splitWords(lemat_text)\n",
    "    bigram_size += countsBigrams(words, bigram_counter, left_counter, right_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "llr_values = []\n",
    "for bigram, val in bigram_counter.items():\n",
    "    llr_values.append((bigram, llr(bigram, val, left_counter, right_counter, bigram_size)))\n",
    "    \n",
    "llr_values.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('mowa', 'subst'), ('art', 'subst')), 66073.48468025675),\n",
       " ((('ustawa', 'subst'), ('dzień', 'subst')), 55238.90386364769),\n",
       " ((('art', 'subst'), ('usta', 'subst')), 50781.10927832162),\n",
       " ((('mowa', 'subst'), ('ust', 'subst')), 29221.301698348656),\n",
       " ((('mowa', 'subst'), ('usta', 'subst')), 19532.092745820457),\n",
       " ((('dzień', 'subst'), ('grudzień', 'subst')), 18010.25392135024),\n",
       " ((('dzień', 'subst'), ('styczeń', 'subst')), 16750.926922731625),\n",
       " ((('jednostka', 'subst'), ('terytorialny', 'adj')), 13286.426732486218),\n",
       " ((('dzień', 'subst'), ('czerwiec', 'subst')), 13242.387222237949),\n",
       " ((('kara', 'subst'), ('wolność', 'subst')), 13136.475933608664),\n",
       " ((('terytorium', 'subst'), ('polski', 'adj')), 12776.67696679245),\n",
       " ((('porozumienie', 'subst'), ('minister', 'subst')), 12214.604681474128),\n",
       " ((('dzień', 'subst'), ('lipiec', 'subst')), 12204.146048841663),\n",
       " ((('termin', 'subst'), ('dzień', 'subst')), 10651.33034336112),\n",
       " ((('dzień', 'subst'), ('sierpień', 'subst')), 10244.026619823593),\n",
       " ((('emerytura', 'subst'), ('renta', 'subst')), 9246.639262889725),\n",
       " ((('dzień', 'subst'), ('kwiecień', 'subst')), 9114.766178470662),\n",
       " ((('dzień', 'subst'), ('wrzesień', 'subst')), 8826.139782244174),\n",
       " ((('dzień', 'subst'), ('październik', 'subst')), 8690.623212381592),\n",
       " ((('dzień', 'subst'), ('listopad', 'subst')), 8607.3278443828),\n",
       " ((('miesiąc', 'subst'), ('dzień', 'subst')), 7714.051002893903),\n",
       " ((('sprawa', 'subst'), ('publiczny', 'adj')), 7522.807444291716),\n",
       " ((('życie', 'subst'), ('upływ', 'subst')), 7518.903705142561),\n",
       " ((('dzień', 'subst'), ('maj', 'subst')), 7383.7038049090725),\n",
       " ((('minister', 'subst'), ('narodowy', 'adj')), 7251.892273290338),\n",
       " ((('dzień', 'subst'), ('marzec', 'subst')), 7039.250221325792),\n",
       " ((('dzień', 'subst'), ('dzień', 'subst')), 6813.727009823763),\n",
       " ((('imię', 'subst'), ('nazwisko', 'subst')), 6503.884776355396),\n",
       " ((('droga', 'subst'), ('szczegółowy', 'adj')), 6398.975576146533),\n",
       " ((('zakład', 'subst'), ('zdrowotny', 'adj')), 6170.233484757883),\n",
       " ((('państwo', 'subst'), ('unia', 'subst')), 6020.64559371326),\n",
       " ((('ust', 'subst'), ('wyraz', 'subst')), 5737.008402655638),\n",
       " ((('prezes', 'subst'), ('minister', 'subst')), 5611.707614882433),\n",
       " ((('zmiana', 'subst'), ('jednolity', 'adj')), 5219.347452129553),\n",
       " ((('dzień', 'subst'), ('luty', 'subst')), 5129.202286380145),\n",
       " ((('wpis', 'subst'), ('rejestr', 'subst')), 5096.1865949045305),\n",
       " ((('towar', 'subst'), ('usługa', 'subst')), 4986.093150714989),\n",
       " ((('komendant', 'subst'), ('policja', 'subst')), 4459.250713969694),\n",
       " ((('organ', 'subst'), ('rządowy', 'adj')), 4226.995965180522),\n",
       " ((('upływ', 'subst'), ('dzień', 'subst')), 4150.58778669099),\n",
       " ((('życie', 'subst'), ('ustawa', 'subst')), 4112.593504730013),\n",
       " ((('brzmienie', 'subst'), ('minister', 'subst')), 4041.437709395203),\n",
       " ((('font', 'subst'), ('font', 'subst')), 4023.4263227551605),\n",
       " ((('składka', 'subst'), ('ubezpieczenie', 'subst')), 4015.3201638632427),\n",
       " ((('dziennik', 'subst'), ('rzeczpospolita', 'subst')), 4011.451253807956),\n",
       " ((('wolność', 'subst'), ('rok', 'subst')), 4000.3219269514852),\n",
       " ((('niezdolność', 'subst'), ('praca', 'subst')), 3948.0689168236795),\n",
       " ((('tkanka', 'subst'), ('komórka', 'subst')), 3858.98647591499),\n",
       " ((('życie', 'subst'), ('dzień', 'subst')), 3598.25860966666),\n",
       " ((('termin', 'subst'), ('miesiąc', 'subst')), 3478.126701877965)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_llr_values = list(filter(lambda x: x[0][0][1] == 'subst' and x[0][1][1] in ['subst', 'adj'], llr_values))\n",
    "filter_llr_values[:50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
