{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Compute **bigram** counts in the corpora, ignoring bigrams which contain at least one token that is not a word\n",
    "   (it contains characters other than letters). The text has to be properly normalized before the counts are computed:\n",
    "   it should be downcased and all punctuation should be removed. Given the sentence: \"The quick brown fox jumps over the\n",
    "   lazy dog\", the bigram counts are as follows:\n",
    "   1. \"the quick\": 1\n",
    "   1. \"quick brown\": 1\n",
    "   1. \"brown fox\": 1\n",
    "   1. etc.\n",
    "1. Use [pointwise mutual information](https://en.wikipedia.org/wiki/Pointwise_mutual_information) to compute the measure \n",
    "   for all pairs of words. \n",
    "1. Sort the word pairs according to that measure in the descending order and display 30 top results.\n",
    "1. Use [log likelihood ratio](http://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html) (LLR) to compute the measure\n",
    "   for all pairs of words.\n",
    "1. Sort the word pairs according to that measure in the descending order and display 30 top results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import regex\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def filesNames():\n",
    "    path = '../ustawy'\n",
    "    absolute_path = os.path.realpath(path) + \"\\\\\"\n",
    "    return [(absolute_path + filename, filename) for filename in os.listdir(path)]\n",
    "\n",
    "def getFileTextRaw(path):\n",
    "    with open(path, 'r', encoding=\"utf8\") as content_file:\n",
    "        return content_file.read()\n",
    "    \n",
    "def cleanText(text):\n",
    "    lower_text = text.replace('-\\n', '').replace('\\n', ' ').lower()\n",
    "    unpunct_text = regex.sub(r\"\\p{P}\", ' ' ,lower_text)\n",
    "    without_empty_text = regex.sub(r\"\\s+\", ' ' ,unpunct_text).strip()\n",
    "    return without_empty_text\n",
    "\n",
    "def splitWords(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "def correctWord(word):\n",
    "    return word.isalpha()\n",
    "\n",
    "def countsBigrams(words, bigram_counter, left_counter, right_counter):\n",
    "    bigram_size = 0\n",
    "    for index, right_word in enumerate(words[1:]):\n",
    "        left_word = words[index-1]\n",
    "        if correctWord(right_word) and correctWord(left_word):\n",
    "            bigram_counter[(left_word, right_word)] += 1\n",
    "            left_counter[left_word] +=1\n",
    "            right_counter[right_word] +=1\n",
    "            bigram_size += 1\n",
    "    return bigram_size\n",
    "\n",
    "def shannon(values, N):\n",
    "    return sum([k / N * math.log(k/N + (k == 0)) for k in values])\n",
    "\n",
    "def pmi(bigram, val, left_counter, right_counter, bigram_size):\n",
    "    return math.log((val*bigram_size)/(left_counter[bigram[0]]*right_counter[bigram[1]]))\n",
    "\n",
    "def llr(bigram, val, left_counter, right_counter, bigram_size):\n",
    "    k_11 = val\n",
    "    k_12 = right_counter[bigram[1]] - val\n",
    "    k_21 = left_counter[bigram[0]] - val\n",
    "    k_22 = bigram_size - right_counter[bigram[1]] - left_counter[bigram[0]] + val\n",
    "    return 2 * bigram_size * (shannon([k_11, k_12, k_21, k_22], bigram_size) - shannon([k_11 + k_12, k_21 + k_22], bigram_size) - shannon([k_11 + k_21, k_12 + k_22], bigram_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counter = Counter()\n",
    "left_counter = Counter()\n",
    "right_counter = Counter()\n",
    "bigram_size = 0\n",
    "for (path, filename) in filesNames():\n",
    "    content = getFileTextRaw(path)\n",
    "    clean_text = cleanText(content)\n",
    "    words = splitWords(clean_text)\n",
    "    bigram_size += countsBigrams(words, bigram_counter, left_counter, right_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_values = []\n",
    "llr_values = []\n",
    "for bigram, val in bigram_counter.items():\n",
    "    pmi_values.append((bigram, pmi(bigram, val, left_counter, right_counter, bigram_size)))\n",
    "    llr_values.append((bigram, llr(bigram, val, left_counter, right_counter, bigram_size)))\n",
    "    \n",
    "pmi_values.sort(key=lambda x: -x[1])\n",
    "llr_values.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('â', 'ť'), 14.991845326195742),\n",
       " (('č', 'á'), 14.991845326195742),\n",
       " (('jednoosiowe', 'dwuosiowe'), 14.991845326195742),\n",
       " (('mierzenia', 'tętniczego'), 14.991845326195742),\n",
       " (('mundurowe', 'zuchów'), 14.991845326195742),\n",
       " (('zuchów', 'harcerzy'), 14.991845326195742),\n",
       " (('łączniki', 'instala'), 14.991845326195742),\n",
       " (('zbiornikowe', 'wyłą'), 14.991845326195742),\n",
       " (('rozdzielczych', 'sterowni'), 14.991845326195742),\n",
       " (('aluminiowe', 'stalowo'), 14.991845326195742),\n",
       " (('polistyrenu', 'styro'), 14.991845326195742),\n",
       " (('otworowa', 'okręto'), 14.991845326195742),\n",
       " (('chirurgicznymi', 'terapeutycznymi'), 14.991845326195742),\n",
       " (('wyczerpująco', 'znawca'), 14.991845326195742),\n",
       " (('przykładem', 'przykładami'), 14.991845326195742),\n",
       " (('ornament', 'kolorystyczna'), 14.991845326195742),\n",
       " (('niewielkim', 'używała'), 14.991845326195742),\n",
       " (('jednoroczne', 'kilkuletnie'), 14.991845326195742),\n",
       " (('profesorem', 'doktorem'), 14.991845326195742),\n",
       " (('napisami', 'rysunkami'), 14.991845326195742),\n",
       " (('posługującego', 'podwykonawcami'), 14.991845326195742),\n",
       " (('wymazywania', 'przeróbek'), 14.991845326195742),\n",
       " (('biernymi', 'międzyokresowymi'), 14.991845326195742),\n",
       " (('akceptowanych', 'indosowanych'), 14.991845326195742),\n",
       " (('piekarskich', 'ciastkar'), 14.991845326195742),\n",
       " (('stołami', 'rulety'), 14.991845326195742),\n",
       " (('uzyskałyby', 'umocniły'), 14.991845326195742),\n",
       " (('śródleśnej', 'wrzosowiska'), 14.991845326195742),\n",
       " (('iskrzeniem', 'roznieca'), 14.991845326195742),\n",
       " (('zapałki', 'niedopałki'), 14.991845326195742)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_values[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('nr', 'poz'), 442015.687847785),\n",
       " (('o', 'mowa'), 236957.99311387417),\n",
       " (('z', 'r'), 110797.77464841149),\n",
       " (('poz', 'nr'), 94571.8434153988),\n",
       " (('art', 'ust'), 84422.68761048165),\n",
       " (('mowa', 'ust'), 81666.18210358651),\n",
       " (('mowa', 'art'), 62571.5838482982),\n",
       " (('których', 'w'), 61691.24411003185),\n",
       " (('właściwy', 'spraw'), 49784.834826818565),\n",
       " (('ust', 'pkt'), 48342.47770833059),\n",
       " (('którym', 'w'), 40834.94693266125),\n",
       " (('zastępuje', 'wyrazami'), 39037.67375870713),\n",
       " (('poz', 'z'), 38776.822326526206),\n",
       " (('określi', 'drodze'), 38083.335172063504),\n",
       " (('stosuje', 'odpowiednio'), 35081.66116709625),\n",
       " (('ustawie', 'dnia'), 32412.576681543367),\n",
       " (('wejścia', 'życie'), 31911.969356743804),\n",
       " (('poz', 'i'), 30710.237571577756),\n",
       " (('minister', 'do'), 27699.724904586416),\n",
       " (('w', 'rozporządzenia'), 27277.495598228248),\n",
       " (('wprowadza', 'następujące'), 27216.360156699935),\n",
       " (('dz', 'nr'), 25080.52686877999),\n",
       " (('której', 'w'), 23286.24848648526),\n",
       " (('dz', 'z'), 22755.626099292087),\n",
       " (('ust', 'otrzymuje'), 19691.602580976738),\n",
       " (('porozumieniu', 'ministrem'), 19079.57070400086),\n",
       " (('ustawy', 'dnia'), 19029.329817826743),\n",
       " (('wchodzi', 'życie'), 18437.790265575022),\n",
       " (('grudnia', 'r'), 17456.358627360416),\n",
       " (('dni', 'dnia'), 17000.451714064708)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llr_values[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Answer the following questions:\n",
    "   1. Which measure works better for the problem?\n",
    "   1. What would be needed, besides good measure, to build a dictionary of multiword expressions?\n",
    "   1. Can you identify a certain threshold which clearly divides the *good* expressions from the *bad*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: \n",
    "PMI was not working, maybe the solution for it would be to make a threshold how many times should the bigram appear to use it, because currently the PMI prefer bigrams with word that only appear once(strange words). LLR is working better thatn PMI but not great either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B: As always the more data we have the better for us. Good text without spellings erros is very important. We could also use lematization to merge expressions, changed by inflection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C: I think that the top 30 results have both bat and good expressions, so th"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
